# Databricks-ETL
ExtraÃ§Ã£o de dados do uber eats

Este projeto tem como objetivo automatizar o processo de ingestÃ£o, transformaÃ§Ã£o e anÃ¡lise de dados do Uber Eats utilizando o Databricks como plataforma principal de dados.
A arquitetura segue o padrÃ£o ELT (Extract, Load, Transform), aproveitando o poder do Delta Lake, PySpark e notebooks Databricks para garantir escalabilidade e performance.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Fonte de Dados (API / CSV / S3) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        [EXTRACT]
               â”‚
        Databricks Ingestion
               â”‚
        [LOAD - Bronze Layer]
               â”‚
        Delta Tables
               â”‚
        [TRANSFORM - Silver/Gold Layers]
               â”‚
        Dashboards / BI / ML

        Etapas Principais do ELT

1. Extract:

Coleta dados do Uber Eats (API ou datasets CSV).
Armazena no Databricks FileStore ou DBFS.

2.Load:

Cria tabelas Delta (camada Bronze).
Implementa controle de versÃ£o e schema evolution.

3.Transform:

Aplica regras de negÃ³cio (normalizaÃ§Ã£o, joins, KPIs).
Gera tabelas Silver e Gold para consumo analÃ­tico.

4. AnÃ¡lise:

CÃ¡lculo de mÃ©tricas: tempo mÃ©dio de entrega, valor mÃ©dio por pedido, top restaurantes, desempenho por regiÃ£o etc.
ConexÃ£o com Power BI para dashboards dinÃ¢micos.

Autor

Wallisson Alencar
ğŸ“§ wallisson.alencar@gmail.com
ğŸ’¼ PÃ³s-graduaÃ§Ã£o em Engenharia de Dados & IA
ğŸ“ Focado em projetos de dados, automaÃ§Ã£o e analytics.
