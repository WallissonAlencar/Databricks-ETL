# Databricks-ETL
ExtraÃ§Ã£o de dados do uber eats

Este projeto tem como objetivo automatizar o processo de ingestÃ£o, transformaÃ§Ã£o e anÃ¡lise de dados do Uber Eats utilizando o Databricks como plataforma principal de dados.
A arquitetura segue o padrÃ£o ELT (Extract, Load, Transform), aproveitando o poder do Delta Lake, PySpark e notebooks Databricks para garantir escalabilidade e performance.

elt-uber-eats-analytics-semana/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_extract_data.py
â”‚   â”œâ”€â”€ 02_load_bronze_delta.py
â”‚   â”œâ”€â”€ 03_transform_silver_gold.py
â”‚   â””â”€â”€ 04_kpi_analysis.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ utils/
    â””â”€â”€ helpers.py



        Etapas Principais do ELT

1. Extract:

Coleta dados do Uber Eats (API ou datasets CSV).
Armazena no Databricks FileStore ou DBFS.

2.Load:

Cria tabelas Delta (camada Bronze).
Implementa controle de versÃ£o e schema evolution.

3.Transform:

Aplica regras de negÃ³cio (normalizaÃ§Ã£o, joins, KPIs).
Gera tabelas Silver e Gold para consumo analÃ­tico.

4. AnÃ¡lise:

CÃ¡lculo de mÃ©tricas: tempo mÃ©dio de entrega, valor mÃ©dio por pedido, top restaurantes, desempenho por regiÃ£o etc.
ConexÃ£o com Power BI para dashboards dinÃ¢micos.

Autor

Wallisson Alencar
ğŸ“§ wallisson.alencar@gmail.com
ğŸ’¼ PÃ³s-graduaÃ§Ã£o em Engenharia de Dados & IA
ğŸ“ Focado em projetos de dados, automaÃ§Ã£o e analytics.
